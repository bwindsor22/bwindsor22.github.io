(this.webpackJsonpsite=this.webpackJsonpsite||[]).push([[0],{155:function(e,n,t){e.exports=t(190)},160:function(e,n,t){},190:function(e,n,t){"use strict";t.r(n);var a=t(0),r=t.n(a),o=t(8),i=t.n(o),s=(t(160),t(24)),l=t(12),c=t(52),d=t(53),h=t(57),m=t(56),u=t(14),p=function(e){Object(h.a)(t,e);var n=Object(m.a)(t);function t(){return Object(c.a)(this,t),n.apply(this,arguments)}return Object(d.a)(t,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement(u.Navbar,null,r.a.createElement(u.NavbarGroup,{align:u.Alignment.LEFT},r.a.createElement(s.b,{to:"/"},r.a.createElement(u.Button,{className:u.Classes.MINIMAL,icon:"home",text:"Home"})),r.a.createElement(s.b,{to:"/articles"},r.a.createElement(u.Button,{className:u.Classes.MINIMAL,icon:"document",text:"Articles"})),r.a.createElement(s.b,{to:"/about"},r.a.createElement(u.Button,{className:u.Classes.MINIMAL,icon:"person",text:"About"})))))}}]),t}(r.a.PureComponent),g=function(){return r.a.createElement("div",{className:".modifier"},r.a.createElement("h1",null," Home page 0 "))},f=t(22),b=t(101),w=t(35),y={"sass-sent-simp":{title:"SASS: Data and Methods for Subject Aware Sentence Simplification",key:"sass-sent-simp",date:"2020-12-14",tags:["research"],docBodyHtml:"\n      In a new <a href='https://drive.google.com/file/d/1Rz35LBv15XQRDdiWC5xjcdXUL5GE6GqT/view?usp=sharing'>paper</a> \n      (and <a href='https://docs.google.com/presentation/d/1qyJ1oJRRUXdCz4oTw9wnQpN0jFOR-ZwlgKmDocG3hAI/edit?usp=sharing'>presentation</a>\n      ) under the guidance of Professor <a href='https://hhexiy.github.io/'>He He</a>, we explore an answer to a remarkably pesky question: what does it mean to simplify?\n      <br /> <br />\n      Here's the abstract:\n      <div class=\"bp3-card\">\n        <p class=\".modifier\">\n         Sentence simplification tends to focus on thegeneric simplification of sentences by makingthem more readable and easier to understand.This  paper  provides  a  dataset  aimed  at  train-ing  models  that  perform  subject  aware  sen-tence  simplifications  rather  than  simplifyingsentences as a whole.  We also test models onthat  dataset  which  are  inspired  by  model  ar-chitecture  used  in  abstractive  summarization.We  hand  generated  portions  of  the  data  andaugment  the  dataset  by  further  manipulatingthose hand written simplifications. Our resultsshow  that  data-augmentation,  data-masking,and  model  architecture  choices  used  in  sum-marization provide a solid baseline for compar-ison on subject aware simplification.\n        </p>\n      </div>\n      "},"doc-summ":{title:"Long Document Summarization",key:"doc-summ",date:"2020-12-01",tags:["research"],docBodyHtml:'\n      In a <a href=\'https://drive.google.com/file/d/1QmPOt9YyyWidPOGN4WS5y4Ot0COPCg9x/view?usp=sharing\'>paper</a>\n      still under submission, we outline the task of summarizing long documents with heavy domain-specific words in low-resource settings. We assemble a dataset of public legal briefs and use expert annotations to identify key points, then use a two-step pipeline to extract-then-summarize.\n      This paper was done through my professional work and in collaboration\n      with students at UMass Amherst. \n      \n      <br /> <br />\n        Here\'s the abstract:\n        <br />\n        <div class="bp3-card">\n          <p class=".modifier">\n            Abstractive summarization is the task of compressing a long document into a coherent short document while retaining salient information. Modern abstractive summarization methods are based on deep neural networks which are data hungry algorithms. Since collecting summarization datasets is expensiveand time-consuming task, practical industrial settings are usually low-resource. In this paper, we study a challenging low-resource setting of summarizing long legal briefs with average source document length 4268 words and only 120 available (document, summary) pairs. To account for the data scarcity, we used a modern pretrained abstractive summarizer BART (Lewis et al., 2020), but noticed it is only able to achieve 17.9 ROUGE-L as struggles with long documents. Hence, we attempt to compress these long documents by identifying salient sentences in the source which best ground the summary, using a novel algorithm based on GPT2 (Radford et al., 2019) language model perplexity scores that operates within the low resource regime. On feeding the compressed documents to BART, we observe a 6.0 ROUGE-L improvement, and our method also beats several competitive salience detection baselines. Furthermore, our identified salient sentences tend to agree with an in-dependent human labeling by domain experts.\n          </p>\n           </div>\n      '},"trees-game-1":{title:"Quarantine Project: Photosynthesis",key:"trees-game-1",date:"2020-11-22",tags:["application development"]},"qd-rl-1":{title:"Quality Diversity in Reinforcement Learning: Progress on Work",key:"qd-rl-1",date:"2020-11-22",tags:["research"],docBodyHtml:'\nQuality diversity is a school of reinforcement learning algorithms which maintain an abundance of good-yet-different\nsolutions rather than optimize for a specific goal. <br /> <br />\nIn our a working <a href="https://drive.google.com/file/d/1HCDLNPCOfb9KzZUyT5pWELu1FIaBUL6x/view?usp=sharing"> paper </a>\nwith Prof Julian Togelius, we explore how members of this class of of algorithms can outperform simple evolutionary search.\n<br /> <br />\nOur paper is essentially a negative result; for our toy problem, we have yet to find meaningful improvements.\nHowever, we do come away with a better characterization of these algorithms, and promising directions for our continued work.\n  \n<br /> <br />\nHere\'s the abstract:\n<br />\n<div class="bp3-card">\n  <p class=".modifier">\nThe Reinforcement Learning field is strong on achievements and weak\non reapplication; a computer playing GO at a super-human level is still\nterrible at Tic-Tac-Toe. This paper asks whether the method of training\nnetworks improves their generalization. Specifically we explore core quality\n diversity algorithms, compare against two recent algorithms, and propose\n  two new algorithms to deal with shortcomings in existing methods.\nOur work raises important points about the choice of behavior criterion in\nquality diversity, the interaction of differential and evolutionary training\nmethods, and the role of offline reinforcement learning and randomized\nlearning in evolutionary search.\n      </p>\n    </div>\n      '},"enc-dec":{title:"An Updated Encoder-Decoder Tutorial",key:"enc-dec",date:"2020-11-22",tags:["research","bug report"],docBodyHtml:'\n      I wrote this after seeing Fracois Chollet\'s similar <a href=\'https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\'> encoder-decoder tutorial </a>. \n      Encoder-decoders are fairly universal solutions to sequence to sequence problems, like translation or sentence simplification.\n      <br /> <br />\n      What\'s great about this version?\n        <ul>\n          <li>It uses <a href="https://arxiv.org/abs/1907.11692">Roberta</a>, a well-trained model from the BERT family</li>\n          <li>The Hugging Face <a href="https://huggingface.co/transformers/index.html">transformers</a> will let you upgrade to other models</li>\n          <li>It\'s based on pytorch</li>\n          <li>There are two toy problems for testing encoder-decoder training, based on the num2words package</li>\n        </ul>\n      See Training and Evaluation Code, and bottom for other details. <br />\n      <h3>Training and Evaluation code</h3>\n      <Pre>\nimport logging\nimport random\nimport torch\nfrom num2words import num2words\nfrom transformers import EncoderDecoderModel, RobertaTokenizer, AdamW\n\n"""\nPARAMETERS AND LOGGING\n"""\nmodel_name = \'roberta-base\'\nrun_name = \'numbers\'\n\nepochs = 50\nbatch_size = 64\nlearning_rate = 3e-5\ndevice = \'cpu\'\n\nlog_file_name = \'./{}-{}-epch-{}-batch-{}-lr-{}-out.log\'.format(run_name, model_name, epochs, batch_size, learning_rate)\nlogging.basicConfig(filename=log_file_name, level=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler())\n\n"""\nDATASETS\n"""\ndef say_numbers():\n    """\n    100 -> one hundred\n    """\n    amount = 500\n    data = [\n        (str(i), num2words(i))\n        for i in range(amount)\n    ]\n    random.shuffle(data)\n\n    return data\n\ndef count_next_number():\n    """\n    one hundred -> one hundred and one\n    """\n    amount = 501\n    data = [num2words(i) for i in range(amount)]\n    paired = [(d1, d2) for d1, d2 in zip(data, data[1:])]\n    return paired\n\n\ndef eng_fra_data():\n    """\n    one -> un\n    curl -O http://www.manythings.org/anki/fra-eng.zip\n    unzip fra-eng.zip\n    """\n    data_path = \'./fra.txt\'\n    data = []\n    with open(data_path, \'r\', encoding=\'utf-8\') as f:\n        lines = f.read().split(\'\\n\')\n\n        for line in lines[:10000]:\n            input_text, target_text, _ = line.split(\'\\t\')\n            data.append((input_text, target_text))\n\n    return data\n\n\ndef divide_chunks(l, n):\n    # looping till length l\n    for i in range(0, len(l), n):\n        yield l[i:i + n]\n\n\n\n"""\nSET UP TRAINING DATA AND MODEL\n"""\ndef tokenize(text):\n    toks = tokenizer.encode(text)\n    return pad_to_len(toks)\n\n\ndef pad_to_len(toks, max_len=15):\n    if len(toks) <= max_len:\n        return toks + [0] * (max_len - len(toks))\n    return toks[:max_len]\n\n\ndata_encoded = say_numbers()\n\ntrain_len = int(0.9 * len(data_encoded))\ntrain_data = data_encoded[:train_len]\ntest_data = data_encoded[train_len:]\nlogging.info(\'len train %d, len test, %d\', len(train_data), len(test_data))\n\ntokenizer = RobertaTokenizer.from_pretrained(model_name)\nmodel_save_dir = \'/Users/bradwindsor/gs_projects/transformers/training/\'\n\nmodel = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name)\nmodel.train()\nmodel.to(device)\n\n\n"""\nTRAIN\n"""\ntotal_steps = epochs * int(len(train_data) / batch_size)\noptimizer = AdamW(model.parameters(), lr=learning_rate)\n\n# warmup_frac = 0.1\n# scheduler = get_linear_schedule_with_warmup(optimizer, total_steps * warmup_frac, total_steps)\n\nlogging.info(\'first datapoint\')\nlogging.info(str(train_data[0][0]))\nlogging.info(str(tokenize(train_data[0][0])))\nlogging.info(str(train_data[0][1]))\nlogging.info(str(tokenize(train_data[0][1])))\nlogging.info(\'beginning train\')\n\n\nfor epoch in range(epochs):\n    cume_loss = 0\n    for chunk in divide_chunks(train_data, batch_size):\n        inp_ids = torch.tensor([tokenize(e[0]) for e in chunk]).to(device)\n        out_ids = torch.tensor([tokenize(e[1]) for e in chunk]).to(device)\n        optimizer.zero_grad()\n        loss, _, _, _ = model(input_ids=inp_ids, decoder_input_ids=out_ids, labels=out_ids)\n        loss.backward()\n        optimizer.step()\n        # scheduler.step()\n        logging.info(\'...loss %f\', loss.item())\n        cume_loss += loss.item()\n\n    if epoch % 999 == 0:\n        model.save_pretrained(model_save_dir)\n\n    logging.info(\'epoch %d, loss %d\', epoch, cume_loss)\n\n\n"""\nRUN INFERENCE\n"""\ndef run_snip(snip, name):\n    inp_ids = torch.tensor([tokenize(e[0]) for e in snip]).to(device)\n    generated = model.generate(inp_ids, decoder_start_token_id=model.config.decoder.pad_token_id)\n    logging.info(\'%s data %s\', name, str(snip))\n    logging.info(\'generated %s\', str(generated))\n\n    gen = generated.cpu().numpy()\n    for row in gen:\n        logging.info(str(row))\n        logging.info(str(tokenizer.decode(row)))\n\n\nsnip = train_data[:10]\nrun_snip(snip, \'train\')\nsnip = test_data[:10]\nrun_snip(snip, \'test\')\n</Pre>\n<h3>Modifications to use a local or pretrained model</h3>\nHuggingface will automatically download Roberta, but perhaps you want to use a pretrained model. In that case, do this:<br /> <br />\n<Pre>\nmodel_path = \'/home/training/roberta-full/\'\ntokenizer = RobertaTokenizer.from_pretrained(model_path)\nencoder_decoder_config = EncoderDecoderConfig.from_pretrained(model_path)\nmodel = EncoderDecoderModel.from_pretrained(model_path, config=encoder_decoder_config)\n</Pre>\n\n\n'},"005":{title:"Javascript and Python Rosetta Stone",key:"005",date:"2020-08-09",tags:["application development"],docBodyHtml:'\n      For the many people who learn either python or javascript, it is worth noting that\n      how incredibly close you are to using the other. One reason is that JSON is the\n      language of REST calls and as such, both languages deal with lists\n      [] and maps {}. Here is an abridged translation:\n      <table class="bp3-html-table .modifier">\n        <thead>\n          <tr>\n            <th>Task</th>\n            <th>Python</th>\n            <th>Javascript</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>Create and filter a list</td>\n            <td>\n<Pre>\na = [1, 2, 3, 4]\n[n for n in a if not n % 2 == 0]\n\n<i>[1, 3]</i>\n</Pre>\n            </td>\n            <td>\n<Pre>\nlet a = [1, 2, 3, 4];\na.filter(n => n % 2 !=0);\n\n<i>[1, 3]</i>\n</Pre>\n            </td>\n          </tr>\n          <tr>\n            <td>Create two maps and merge them</td>\n            <td>\n<Pre>\none = {\'a\': 1}\ntwo = {\'b\': b}\n{**one, **two}\n\n<i>{a: 1, b: 2}</i>\n</Pre>\n            </td>\n            <td>\n<Pre>\nlet one = {\'a\': 1}\nlet two = {\'b\': b}\n{...one, ...two}\n\n<i>{a: 1, b: 2}</i>\n</Pre>\n            </td>\n          </tr>\n          <tr>\n            <td>Print each element in <br />\n             a list with a running counter</td>\n            <td>\n<Pre>\na = [1, 2, 3, 4]\nfor i, ele in enumerate(a):\n    print(ele, i)\n\n\n<i>1, 0...</i>\n</Pre>\n            </td>\n            <td>\n<Pre>\nlet a = [1, 2, 3, 4];\na.forEach((ele, i) => {\n    console.log(ele, i);\n}\n\n<i>1, 0...</i>\n</Pre>\n            </td>\n          </tr>\n          <tr>\n            <td>Sort then map</td>\n            <td>\n<Pre>\ncities = [{"city":"new york", "land_area":302.6},\n          {"city":"seattle", "land_area":83.9},\n          {"city":"kansas city", "land_area":315}]]\ncities = sorted(cities, key=lambda x: x[\u2018land_area\u2019])\ncities = [c[\u2018city\u2019] for c in cities]\n\n\n<i>[\u2018new york\u2019, \u2018seattle\u2019, \u2018kansas city\u2019]</i>\n</Pre>\n            </td>\n            <td>\n<Pre>\nlet cities = [{"city":"new york", "land_area":302.6},\n              {"city":"seattle", "land_area":83.9},\n              {"city":"kansas city", "land_area":315}];\n\ncities = cities.sort((a, b) =>  {a.land_area - b.land_area})\n               .map((d)  => d.city );\n\n<i>[\u2018new york\u2019, \u2018seattle\u2019, \u2018kansas city\u2019]</i>\n</Pre>\n            </td>\n          </tr>\n          <tr>\n            <td>Accumulate on each <br />\n             element of a list</td>\n            <td>\n<Pre>\narea_km = 0\nfor d in cities:\n    area_km += d[\u2018land_area\u2019] * 2.6\n\n<i>1823.9</i>\n</Pre>\n            </td>\n            <td>\n<Pre>\nlet areas_km = cities.reduce( (acc, d) => {\n                          acc += d.land_area * 2.6;\n                      }, 0);\n\n<i>1823.9</i>\n</Pre>\n            </td>\n          </tr>\n        </tbody>\n      </table>\n      '},"004":{title:"4 Problems in NLP We've Tried to Solve But Haven't Yet",key:"004",date:"2020-07-03",tags:["research"],docBodyHtml:"\n      We've solved the Turing test: since 1980 there have been computers\n      which we can't tell apart from humans. We have Alexa in our homes,\n      Google answers our questions, Siri pulls up our favorite songs or movies on command.\n      With so much done, what is there in NLP which we can't yet do?\n      <br /><br /><h4>Technical question answering</h4>\n      A computer can't answer quetions like 'Why is Microsoft Word broken?'. See the <a href='https://www.aclweb.org/anthology/W15-4640.pdf'>\n      Ubuntu dialogue corpus</a>; attempts to provide helpful answers are at <a href='https://arxiv.org/pdf/2003.04976.pdf'>\n      5% F1</a>, or the <a href='https://leaderboard.techqa.us-east.containers.appdomain.cloud'/>\n      IBM TechQA dataset</a>, where results are working ~50% of the time.\n      <br /> <br />\n      While <a href='https://arxiv.org/pdf/1909.01958.pdf'>\n      getting an \"A\" on a 12-th grade science exam</a>\n      is a notable example of solving hard questions with a book as reference, and there are some attempts to build bots to\n      <a href='https://www.techrepublic.com/article/want-to-be-a-better-programmer-try-microsofts-code-writing-question-answering-stack-overflow-bot/'>\n      help answer Stack Overflow questions</a>,\n      we are a long way from doing this for any domain and reference material.\n      <br /> <br />Lastly, the best answer to \"Why isn't my Arch installation working?\" might begin,\n      \"Do you see your bootloader start on startup?\" dialogue and investigation are part of any help desk.\n\n      <br /><br /><h4>Lifelong Learning</h4>\n      Given enough data, we can teach a network to do anything. Do we always need new data to do new things though?\n      <br />\n      Reusing past learning is arguably the goal of expressing knowledge in an explicit format (as with knowledge bases or formal logic)\n      or language models. And while there is evidence with <a href='https://arxiv.org/pdf/2005.14165.pdf'>GPT-3</a> that sufficient pre-training on\n      large enough corposes of text can help solve many problems with just a few (or one) examples,\n      much neural network fine-tuning suffers from a problem called \"catastrophic forgetting\";\n      the more you train for one task, the less suited you are for another.\n      <br />\n      Having a system which continuously accumulates knowledge from prior tasks and uses it for future tasks\n      is the goal of a paradigm known as <a href='https://www.cs.uic.edu/~liub/lifelong-machine-learning-draft.pdf'>\n      lifelong learning</a> (a superset of transfer learning), and it is, as of yet, unsolved.\n\n      <br /><br /><h4>A Persuasive AI </h4>\n      I know, I know, IBM's Project Debater <a href='https://www.youtube.com/watch?v=m3u-1yttrVw'>won a broadcast debate against a human</a>. Yet the constraints in that debate (has to be Wikipedia-referenceable)\n      and in the debate's sub-genre (nothing open-ended like \"propose a plan to do X\"), as well as\n      IBM's own continuing work on this topic,\n      point to this being an unfinished area. More generally, these efforts\n      seem focused on appearing logical to a panel of impartial judges -- anyone who's ever\n      tried to <a href='https://genius.com/The-fray-how-to-save-a-life-lyrics'>convince a friend</a>\n      knows changinging viewpoints is a matter of facts, feelings, motivations, and personal experiences.\n      You might even start by <a href='https://mygestaltherapy.com/what-is-the-socratic-method-how-to-persuade-anyone/'>\n      accepting their view</a>.\n      <br /> <br />\n      When Alexa can persuade me I should exercise today, I should change my political party, take one\n      job offer over another, or make peace with the person I'm fighting, that will feel like a different AI.\n\n      <br /><br /><h4>Explain like I'm 5 </h4>\n      \"If you truly understand your PhD Thesis, you'll be able to explain it to a\n      5-year old.\" While there are\n      <a href='https://www.quora.com/What-is-your-PhD-thesis-in-one-sentence'>\n        multiple\n      </a>\n      <a href='https://lolmythesis.com/'>\n        websites\n      </a>\n      devoted to this, we're pretty far from being able to read a scientific\n      paper (\"Subjective Social Status and Major  Depression: A Path Analysis of\n      Biological and Psychosocial Mechanisms\") and re-express it in common terms\n      (\"Feeling nervous about what others think of you makes you depressed.\")\n      There's at least <a href='https://research.fb.com/wp-content/uploads/2019/07/ELI5-Long-Form-Question-Answering.pdf'>one paper</a>,\n      and much related work in abstractive summarization and\n      sentence simplification, but both are incomplete.\n\n      <br /><br /><h4>And every other</h4>\n      The problem space of natural language processing is anything which has\n      been accomplished with writing or spoken word. Anything which has been done with human words or thoughts,\n      and not yet with a computer, is an unsolved part.\n      "},"003":{key:"003",title:"New Paper: Causality and Batch RL",date:"2020-06-03",tags:["research"],docBodyHtml:"\n        Written with professor Joan Bruna in the <a href='http://mathsdl-spring20.willwhitney.com/'>Mathematics of Deep Learning course</a>,\n        our group released a <a href='https://arxiv.org/abs/2006.02579'>paper</a>\n         about the intersection of two different fields related to AI:\n        <a href='https://en.wikipedia.org/wiki/Causality'>causality</a> and offline (batch)\n        <a href='https://en.wikipedia.org/wiki/Reinforcement_learning'>reinforcment learning</a>.\n        We argue that these are different fields which tackle the same problem with similar\n        mathematical models.\n\n\n        <br /> <br />\n        Here's the abstract:\n        <br />\n        <div class=\"bp3-card\">\n          <p class=\".modifier\">\n            Reinforcement learning algorithms have had tremendous successes in online learning settings.\n            However, these successes have relied on low-stakes interactions between the algorithmic agent and its environment.\n            In many settings where RL could be of use, such as health care and autonomous driving, the mistakes made by most online RL algorithms during early training come with unacceptable costs.\n            These settings require developing reinforcement learning algorithms that can operate in the so-called batch setting, where the algorithms must learn from set of data that is fixed, finite, and generated from some (possibly unknown) policy.\n            Evaluating policies different from the one that collected the data is called off-policy evaluation, and naturally poses counter-factual questions. In this project we show how off-policy evaluation and the estimation of treatment effects in causal inference are two approaches to the same problem, and compare recent progress in these two areas.\n          </p>\n        </div>\n      "},"002":{key:"002",title:"How to handle the 'I have an App idea, can you help?' conversation",date:"2020-03-01",docBodyHtml:"\n      Having someone from a business school pitch an app idea is a common-enough situation to merit its own\n      <a href='https://whartoniteseekscodemonkey-blog.tumblr.com/'>tumblr blog</a>\n      and <a href='https://www.reddit.com/r/AskReddit/comments/fknqc2/coders_of_reddit_how_do_you_politely_refuse_your/'>\n        Reddit threads</a>, many of which are less than helpful.\n      <br /> <br />\n      Let's instead consider instead how great it is to have people who thinking creatively about technology and new applications.\n      Next time someone reaches out to you about an app idea, <strong>show them the steps to prove their idea is a great one.</strong> This might look like:\n      <ul>\n      <li>Use Invisionapp or the like to build a mock-up that looks and acts like the real thing</li>\n      <li>Show the mock-up to everyone they know and watch how users interact with it</li>\n      <li>Make a market research survey get people to fill it out</li>\n      <li>Drop $100 on internet ads to see the level of interest you get</li>\n      </ul>\n      A product manager can do much of the product design and business planning without an engineer. And if they assemble the evidence and test the design, who knows, someone might build it.\n\n      ",tags:["application development"]},"001":{key:"001",title:"So why include that package-lock.json?",date:"2019-10-01",tags:["bug report","application development"],docBodyHtml:"\n      In javascript, package-lock.json seems a fairly extraneous byproduct of npm's build system. At first it seems like you wouldn't want to add it to your repo:\n      <ol>\n        <li>package-lock.json isn't used by the application to run at all </li>\n        <li>package-lock.json gets regenerated when you run npm install, which you'll do anyway </li>\n        <li>package-lock.json can actually make it harder to run an install, if some of your libraries have more recent versions you have to\n        remove package-lock.json before an install will work.</li>\n      </ol>\n      <br />\n      Yet there's one really good reason why you should ignore all the above and absolutely include it:\n      <ol>\n        <li>package-lock.json records exactly which package you installed. If you did npm install <package-name>@latest --save-dev,\n        it probably looks something like this in your package.json: \"<package-name>\": \"*\".\n        <br />\n        Six months from now, when all of your build tools have changed, and the app somehow mysteriously stopped working,\n        you'll need to know what exact package version was that \"*\" when it last worked. And you're not going to know that unless you checked in package-lock.json\n        </li>\n      </ol>\n      "}},v=function(){return Object(b.a)(new Set(Object.values(y).flatMap((function(e){return e.tags}))))},k=Object(w.b)({name:"articleIndex",initialState:{articles:Object.values(y),selectedArticles:[],selectedTags:[],allTags:v(),colorMap:function(){var e=v(),n=["#a28089","#33cc33","#1d2d50","#133b5c","#1e5f74","#8458B3"];return e.reduce((function(e,t,a){return e[t]=n[a],e}),{})}()},reducers:{setSelection:function(e,n){if(e.selectedTags=n.payload,n.payload){var t=new Set(n.payload.map((function(e){return e.value})));e.selectedArticles=e.articles.filter((function(e){return e.tags.filter((function(e){return t.has(e)})).length>0}))}else e.selectedArticles=e.articles},decrement:function(e){e.value-=1},incrementByAmount:function(e,n){e.value+=n.payload}}}),_=k.actions,E=(_.decrement,_.incrementByAmount,_.setSelection),x=k.reducer,I=t(193),A=t(194),T=t(195),P=t(100),j=function(e){var n=e.article,t=e.colorMap,a=Object(l.f)(),o=n.date,i=(n.docBodyHtml,n.key),s=n.tags,c=n.title;return r.a.createElement("div",null,r.a.createElement("h4",null,r.a.createElement("a",{onClick:function(){return a.push("/article/".concat(i))},style:{color:"#007bff"}},c)),r.a.createElement("p",null,o),r.a.createElement("p",null,s.map((function(e){return r.a.createElement(u.Tag,{style:{background:t[e],marginRight:5}},e)}))))};function O(){var e=Object(f.d)((function(e){return e.articleIndex.articles})),n=Object(f.d)((function(e){return e.articleIndex.selectedArticles})),t=Object(f.d)((function(e){return e.articleIndex.allTags})),a=Object(f.d)((function(e){return e.articleIndex.colorMap})),o=(Object(f.d)((function(e){return e.articleIndex.selectedTags})),Object(f.c)()),i=t.map((function(e){return{value:e,label:e}}));return r.a.createElement("div",null,r.a.createElement(I.a,null,r.a.createElement(A.a,null,r.a.createElement(T.a,null,r.a.createElement("h3",null,"Articles"))),r.a.createElement(A.a,null,r.a.createElement(T.a,{xs:7,md:9},(n.length>0?n:e).map((function(e){return r.a.createElement(j,{article:e,colorMap:a})}))),r.a.createElement(T.a,{xs:5,md:3},r.a.createElement("p",null,"Filter by tag"),r.a.createElement(P.a,{options:i,isMulti:!0,onChange:function(e){return o(E(e))}})))))}var z=t(98),S=t(97),M=t.n(S),B=function(){return r.a.createElement("div",null,r.a.createElement(I.a,null,r.a.createElement(A.a,null,r.a.createElement("h4",null,"Quarantine Project: Photosynthesis")),r.a.createElement(A.a,null,r.a.createElement(T.a,{xs:6},"A wonderful ",r.a.createElement("a",{href:"https://www.amazon.com/Blue-Orange-Games-Photosynthesis-Strategy/dp/B074K5W5N5/ref=sr_1_2?crid=24LNH0NN4FP3S&dchild=1&keywords=photosynthesis+board+game&qid=1606101325&sprefix=photosynthesis%2Caps%2C265&sr=8-2"},"board game"),', a goal for this quarantined winter is to make "trees chess" playable online.',r.a.createElement("br",null),r.a.createElement("br",null),"What might I learn from this project?",r.a.createElement("ul",null,r.a.createElement("li",null,"React DnD, a more natural user interface"),r.a.createElement("li",null,"There might be some opportunity for doing low-compute AI"),r.a.createElement("li",null,"Running a large-scale web application"),r.a.createElement("li",null,"Most importantly, I will be able to lose to my friends in this again")),r.a.createElement("br",null),"One early discovery: don't try to do something like polar coordinates, rather, put everything as rows with CSS to offset by row number, and have an X-Y coordinate system centered at the board's center."),r.a.createElement(T.a,{xs:6},r.a.createElement(A.a,null,r.a.createElement(z.a,{src:M.a,style:{height:"400px"}})),r.a.createElement(A.a,null,"..a work in in progress..")))))},R={"trees-game-1":r.a.createElement(B,null)},H=function(e){Object(h.a)(t,e);var n=Object(m.a)(t);function t(){return Object(c.a)(this,t),n.apply(this,arguments)}return Object(d.a)(t,[{key:"render",value:function(){var e=this.props,n=e.articleKey,t=e.colorMap,a=e.state;return console.log(R),n in R?R[n]:n in y?function(e){var n=e.article,t=e.colorMap,a=n.title,o=n.date,i=n.docBodyHtml,l=n.tags;return r.a.createElement(T.a,null,r.a.createElement(A.a,null,r.a.createElement(T.a,null,r.a.createElement("h4",null,a),r.a.createElement("p",null,o),r.a.createElement("p",null,l.map((function(e){return r.a.createElement(u.Tag,{style:{background:t[e],marginRight:5}},e)}))),r.a.createElement("div",{dangerouslySetInnerHTML:{__html:i}}),r.a.createElement("br",null),r.a.createElement(s.b,{to:"/articles"},r.a.createElement(u.Button,null,"Back to list")))))}({article:y[n],colorMap:t}):r.a.createElement("div",null,"`No article found with key ",n,".`",JSON.stringify(a))}}]),t}(r.a.Component);var N=Object(f.b)((function(e,n){var t=e.articleIndex.colorMap;return{articleKey:n.match.params.articleKey,colorMap:t,state:e}}))(H),L=t(99),W=t.n(L),C=function(){var e=window.innerWidth<400;return r.a.createElement(T.a,null,r.a.createElement(A.a,null,r.a.createElement(T.a,null,r.a.createElement("img",{src:W.a})),r.a.createElement(T.a,{style:{display:"flex",alignItems:"center"}},r.a.createElement("p",{style:{color:e?"white":"black",size:e?12:20,fontWeight:e?"bold":"normal"}},r.a.createElement("i",null,"Each day a step at a time.")))))},D=function(){return r.a.createElement(I.a,null,r.a.createElement(T.a,null,r.a.createElement("div",null,r.a.createElement("h1",null," About "),r.a.createElement("p",null," Hello! I'm Brad! I like code and I like people. On this blog I talk about programming, expecially the things I'm learning through my master's program. Opinions are my own. "),r.a.createElement("h4",null," Career "),r.a.createElement("p",null," I work on natural language processing in finance. In the past I've been a project manager and data engineer. "),r.a.createElement("h4",null," Volunteer "),r.a.createElement("p",null," I've taught ",r.a.createElement("a",{href:"https://www.microsoft.com/en-us/teals"},"computer science in a highschool"),",\xa0",r.a.createElement("a",{href:"https://www.digital.nyc/investors/deltanyc-better-pro-bono-tech"},"consulted pro-bono"),",\xa0",r.a.createElement("a",{href:"https://github.com/bwindsor22/speechr"},"tracked hate speech"),",\xa0 and been the voice at the end of a ",r.a.createElement("a",{href:"https://samaritansnyc.org/24-hour-crisis-hotline/"},"suicide hotline"),". Economic mobility and mental health are my causes of choice."),r.a.createElement("h4",null," Spare Time "),r.a.createElement("p",null," Talk to me about glass blowing, marathons, pop music, or any ",r.a.createElement("a",{href:"https://a24films.com/films"},"movie by A24"),"."),r.a.createElement("h4",null," More About "),r.a.createElement("p",null," You can follow me on ",r.a.createElement("a",{href:"https://twitter.com/windsor_brad"},"twitter"),", ",r.a.createElement("a",{href:"https://www.linkedin.com/in/brad-windsor-3ba33727/"},"LinkedIn"),", or ",r.a.createElement("a",{href:"https://github.com/bwindsor22"},"github"),". My email is bwindsor22@gmail.com."))))};var q=function(){return r.a.createElement("div",{className:"App"},r.a.createElement(s.a,{onUpdate:function(){return window.scrollTo(0,0)}},r.a.createElement(p,null),r.a.createElement(l.c,null,r.a.createElement(l.a,{exact:!0,path:"/",component:C}),r.a.createElement(l.a,{exact:!0,path:"/articles",component:O}),r.a.createElement(l.a,{path:"/article/:articleKey?",component:N}),r.a.createElement(l.a,{exact:!0,path:"/game",component:g}),r.a.createElement(l.a,{exact:!0,path:"/about",component:D}))))},G=Object(w.b)({name:"counter",initialState:{value:0},reducers:{increment:function(e){e.value+=1},decrement:function(e){e.value-=1},incrementByAmount:function(e,n){e.value+=n.payload}}}),F=G.actions,U=(F.increment,F.decrement,F.incrementByAmount,G.reducer),J=Object(w.a)({reducer:{counter:U,articleIndex:x}});Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));t(189);i.a.render(r.a.createElement(r.a.StrictMode,null,r.a.createElement(f.a,{store:J},r.a.createElement(q,null))),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()}))},97:function(e,n,t){e.exports=t.p+"static/media/trees-game.b55e67d5.png"},99:function(e,n,t){e.exports=t.p+"static/media/hike.d8b68062.jpg"}},[[155,1,2]]]);
//# sourceMappingURL=main.a76de343.chunk.js.map